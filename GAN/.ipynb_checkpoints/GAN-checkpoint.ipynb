{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys as sys\n",
    "import random as rd\n",
    "import tensorflow as tf\n",
    "import gzip\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import boto3\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import cStringIO\n",
    "#! sudo pip install s3fs\n",
    "import s3fs\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainSamples(viewers,videos,probab,viewerFeat,videoFeat,contxFeat):\n",
    "    trData = {} # trData = Dictionary with training data. This is histrory of viewer and video iteraction\n",
    "    X = {} # X  = Dictionary with viewer features as arrays\n",
    "    Y ={} # Y  = Dictionary with video features as arrays\n",
    "    for i in range(viewers):\n",
    "        X[i] = np.random.rand(viewerFeat)\n",
    "        a = 0 # timing of the video for a particular user,... \n",
    "                #to give the order in which the videos have been watched\n",
    "        for j in range(videos):\n",
    "            if int(np.random.binomial(1,probab ,1)[0]):\n",
    "                trData[(i,j,a)] = np.random.rand(contxFeat)\n",
    "                a+=1 # when a video is watched, we increase the value of a by 1 \n",
    "            if i==0:\n",
    "                Y[j] = np.random.rand(videoFeat)\n",
    "    return X,Y,trData\n",
    "\n",
    "viewers = 1000  #number of viewers\n",
    "videos = 6000  #number of videos\n",
    "probab = 0.05  #probability of a viewer watching any one video\n",
    "viewerFeat = 310  #number of features describing a veiwer\n",
    "videoFeat = 300   #number of features describing a video\n",
    "contxFeat = 15 # number of contextual features\n",
    "# X  = Dictionary with viewer features as arrays\n",
    "# Y  = Dictionary with video features as arrays\n",
    "# trData = Dictionary with training data. This is histrory of viewer and video iteraction\n",
    "X ,Y ,trData = trainSamples(viewers ,videos ,probab ,viewerFeat ,videoFeat ,contxFeat)\n",
    "\n",
    "user_feat_inp = np.array([X[key] for key in sorted(X.keys())]) \n",
    "vid_feat_inp = np.array([Y[key] for key in sorted(Y.keys())])\n",
    "\n",
    "key_user = np.asarray(range(user_feat_inp.shape[0])).reshape(user_feat_inp.shape[0] ,1)\n",
    "key_vid = np.asarray(range(vid_feat_inp.shape[0])).reshape(vid_feat_inp.shape[0] ,1)\n",
    "user_feat_inp_w_key = np.concatenate((user_feat_inp ,key_user),axis = 1)\n",
    "vid_feat_inp_w_key = np.concatenate((vid_feat_inp ,key_vid),axis = 1)\n",
    "user_vid_time = trData.keys()\n",
    "\n",
    "user_feat_inp_w_key_df = pd.DataFrame(user_feat_inp_w_key) \n",
    "vid_feat_inp_w_key_df = pd.DataFrame(vid_feat_inp_w_key)\n",
    "user_vid_time_df = pd.DataFrame(user_vid_time)\n",
    "\n",
    "rr = user_vid_time_df.sort_values([0 ,2]).reset_index()\n",
    "\n",
    "h = pd.get_dummies(rr[1],prefix = 'vid_')\n",
    "y_tr_p_w = pd.concat([rr.reset_index(drop = True), h], axis = 1)\n",
    "y_tr_p_w.rename(columns = {0: 'user_id'}, inplace = True)\n",
    "y_tr_p_w.rename(columns = {1: 'movie_id'}, inplace = True)\n",
    "y_tr_p_w.rename(columns = {2: 'rank'}, inplace = True)\n",
    "y_tr_p_w['desired'] = np.argmax(np.array(y_tr_p_w.iloc[:,4:]) ,1)\n",
    "\n",
    "max_watch = (y_tr_p_w.groupby('user_id',axis = 0).sum().iloc[:\n",
    "                                ,int(np.array(np.where(y_tr_p_w.columns=='rank'))):-1].sum(axis=1)).reset_index()\n",
    "\n",
    "\n",
    "vid_feat_inp_w_key_df.rename(columns = {300: 'movie_id'}, inplace = True)\n",
    "user_feat_inp_w_key_df.rename(columns = {310: 'user_id'}, inplace = True)\n",
    "user_vid_time_df.rename(columns = {0: 'user_id'}, inplace = True)\n",
    "user_vid_time_df.rename(columns = {1: 'movie_id'}, inplace = True)\n",
    "#user_w_vid_tim_and_feat = user_vid_time_df.merge(user_feat_inp_w_key_df \n",
    "#                                                 ,how = 'inner',on = 'user_id', sort = False)\n",
    "user_vid_time_vidfeat = user_vid_time_df.merge(vid_feat_inp_w_key_df \n",
    "                                                             ,how = 'inner' ,on='movie_id' ,sort = False)\n",
    "user_vid_time_vidfeat.rename(columns={'2_x': 'rank'} ,inplace=True)\n",
    "user_vid_time_vidfeat_sorted = user_vid_time_vidfeat.sort_values(['user_id', 'rank']) \n",
    "\n",
    "\n",
    "# ### Split training and testing data\n",
    "tr_users = viewers * 0.8\n",
    "tr_y = y_tr_p_w[y_tr_p_w['user_id'] < tr_users]\n",
    "te_y = y_tr_p_w[~y_tr_p_w['user_id'].isin(tr_y['user_id'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def block_tri_mat(length, batch_size):\n",
    "    upper_triangular_ones = np.float32(np.triu(np.ones((length, length))))\n",
    "    repeated_tri = np.float32(np.kron(np.eye(batch_size), upper_triangular_ones))\n",
    "    return repeated_tri\n",
    "\n",
    "def np_pad_tr_x(x_tr, batch_size, str_idx, zero_array_x, length_vec):\n",
    "    start = 0\n",
    "    for i in range(batch_size):\n",
    "        if i > 0:\n",
    "            end = end + length_vec[i] \n",
    "        else:\n",
    "            end = length_vec[0]\n",
    "        zero_array_x[ str_idx[i] : (str_idx[i] + length_vec[i]) ] = x_tr[ start : end ] \n",
    "        start = end\n",
    "    return(zero_array_x)\n",
    "\n",
    "\n",
    "def np_pad_tr_x_n_tr_y(x_tr, y_tr, batch_size, str_idx, zero_array_x, zero_array_y, length_vec):\n",
    "    start = 0\n",
    "    for i in range(batch_size):\n",
    "        if i > 0:\n",
    "            end = end + length_vec[i] \n",
    "        else:\n",
    "            end = length_vec[0]\n",
    "        zero_array_x[ str_idx[i] : (str_idx[i] + length_vec[i]) ] = x_tr[ start : end ] \n",
    "        zero_array_y[ str_idx[i] : (str_idx[i] + length_vec[i]) ] = y_tr.iloc[ start : end, (y_tr.shape[1] - 1) ] \n",
    "        start = end\n",
    "\n",
    "    return(zero_array_x, zero_array_y)\n",
    "\n",
    "\n",
    "def range_bet_col_t_col_n_append(col_1 ,col_2):\n",
    "    app_ranges=[]\n",
    "    for i in range(col_1.shape[0]):\n",
    "        single_range = range((col_1[i]).astype(int) ,(col_2[i]).astype(int))\n",
    "        app_ranges = np.append(app_ranges,single_range)\n",
    "    return(app_ranges)\n",
    "\n",
    "\n",
    "def algeb_geom_series(mode ,start ,jump ,length):\n",
    "    u = np.empty((length,))\n",
    "    u[0] = start\n",
    "    u[1:] = jump\n",
    "    if (mode == 0):\n",
    "        series=np.cumsum(u)\n",
    "    if (mode == 1):\n",
    "        series=np.cumprod(u)\n",
    "    return(series)\n",
    "\n",
    "def sort_pd_df_by_ext_vec(df,ext_sor_vec,cols):\n",
    "    df_s = df[((df[cols[0]]).astype(int)).isin(ext_sor_vec)] #\n",
    "    df_s['sort_cat'] = pd.Categorical(df_s[cols[0]],categories = ext_sor_vec,ordered = True)\n",
    "    if len(cols) > 1:\n",
    "        df_s.sort_values(['sort_cat',cols[1]] ,inplace = True)\n",
    "    \n",
    "    else:\n",
    "        df_s.sort_values(['sort_cat'],inplace = True) \n",
    "    \n",
    "    df_s.reset_index(inplace = True)\n",
    "    df_ = df_s.drop(['sort_cat','index'] ,axis = 1)\n",
    "    \n",
    "    return(df_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def attach_zeros_to_np_arr(array ,size_to_att ,axis):\n",
    "    size = size_to_att\n",
    "    if(axis == 0):\n",
    "        new_arr = np.append(array ,np.zeros(size) ,axis = 0)\n",
    "    if(axis == 1):\n",
    "        new_arr = np.concatenate((array ,np.zeros(size)) ,axis = 1)\n",
    "    return(new_arr)\n",
    "\n",
    "\n",
    "def rnn_model(model ,n_hidden ,layers):\n",
    "    if (layers == 1):\n",
    "        if(model == 'lstm'):\n",
    "            try:\n",
    "                cell = tf.nn.rnn_cell.LSTMCell(n_hidden ,state_is_tuple=True,reuse=tf.get_variable_scope().reuse)\n",
    "            except ValueError:\n",
    "                print('yo')\n",
    "                cell = tf.nn.rnn_cell.LSTMCell(n_hidden ,state_is_tuple=True, reuse=True)\n",
    "        else:\n",
    "            cell = tf.nn.rnn_cell.GRUCell(n_hidden)   \n",
    "    else:\n",
    "        if(model == 'lstm'):\n",
    "            lstm = tf.nn.rnn_cell.LSTMCell(n_hidden ,state_is_tuple=True)\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell([lstm]*layers)\n",
    "\n",
    "        else:\n",
    "            gru = tf.nn.rnn_cell.GRUCell(n_hidden)\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell([gru] * layers)\n",
    "    return(cell)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_opt_epoch = 1000\n",
    "model = 'lstm'\n",
    "layers = 1\n",
    "n_samples = 1000\n",
    "top_k = 3\n",
    "n_users = num_users\n",
    "#n_users = 1000\n",
    "#num_users  = n_users\n",
    "te_users = int(np.ceil(num_users*0.2))\n",
    "n_feature = num_video_feat + contex_feat\n",
    "#n_feature = 300\n",
    "#n_feature = num_user_feat + num_video_feat + contex_feat#623\n",
    "n_user_feature = num_user_feat \n",
    "#n_user_feature = 310\n",
    "lr_rat = 0.001 \n",
    "num_video = h.shape[1]\n",
    "beta = 0.01\n",
    "\n",
    "if tr_users > 32:\n",
    "    batch_size = 10\n",
    "else:\n",
    "    batch_size  = tr_users\n",
    "        \n",
    "n_hidden = 32 # hidden layer num of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_opt_epoch = 1000\n",
    "# model = 'lstm'\n",
    "# layers = 1\n",
    "# n_samples = 100\n",
    "# top_k = 30\n",
    "# n_users = num_users\n",
    "# #n_users = 1000\n",
    "# #num_users  = n_users\n",
    "# te_users = int(np.ceil(num_users*0.2))\n",
    "# n_feature = num_video_feat + contex_feat\n",
    "# #n_feature = 300\n",
    "# #n_feature = num_user_feat + num_video_feat + contex_feat#623\n",
    "# n_user_feature = num_user_feat \n",
    "# #n_user_feature = 310\n",
    "# lr_rat = 0.001 \n",
    "# num_video = h.shape[1]\n",
    "# beta = 0.01\n",
    "\n",
    "# if tr_users > 60:\n",
    "#     batch_size = 60\n",
    "# else:\n",
    "#     batch_size  = tr_users\n",
    "        \n",
    "# n_hidden = 32 # hidden layer num of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reward_gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! mkdir -p ./reco_rnn/tensor_plot/GAN/\n",
    "#! mkdir -p ./reco_rnn/GAN/\n",
    "logs_path = \"./reco_rnn/tensor_plot/GAN/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    inp = tf.placeholder(\"float32\" ,[batch_size ,None, num_video] ,name = 'inp') \n",
    "    disc_pred_gen_ph = tf.placeholder(\"float32\" ,[None, 1] ,name = 'inp_ph') \n",
    "    dynam_input = tf.placeholder(\"float32\" ,[batch_size ,None ,n_feature] ,name = 'dynam_input') \n",
    "    const_input = tf.placeholder(\"float32\" ,[batch_size, n_user_feature] ,name = 'const_input') \n",
    "    y_true = tf.placeholder(\"int32\",[None, 1] ,name = 'Input_y')\n",
    "    max_batch_length = tf.placeholder(\"float32\" ,[batch_size] ,name = 'max_leng')\n",
    "    tr_rw = tf.placeholder(\"int32\" ,[None, 1] ,name = '_rw')\n",
    "    tr_rw_n_desired_rep = tf.placeholder(\"int32\" ,[None, 2] ,name = 'rw_rep')\n",
    "    rows_t = tf.placeholder(\"float32\" ,[None] ,name = 'rw_rep_t')\n",
    "    _maxx = tf.placeholder(\"int32\" ,name = 'maxx')\n",
    "    block_mat = tf.placeholder(\"float32\",[None, None] ,name = 'block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"weights\"):\n",
    "    W_gener_co = tf.get_variable(\"variable1\", shape=[n_user_feature ,num_video]\n",
    "                                        , initializer=tf.random_normal_initializer(), dtype='float32')\n",
    "    W_gener_ou = tf.get_variable(\"variable2\" ,shape=([n_hidden ,num_video])\n",
    "                                        , initializer=tf.random_normal_initializer(), dtype='float32')\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    assert tf.get_variable_scope().reuse==True\n",
    "\n",
    "    W_gener_co_2 = tf.get_variable(\"variable1\",shape=[n_user_feature, num_video]\n",
    "                                          , dtype='float32')\n",
    "    W_gener_ou_2 = tf.get_variable(\"variable2\", shape=[n_hidden, num_video]\n",
    "                                   , dtype='float32')\n",
    "\n",
    "with tf.variable_scope(\"biases\"):\n",
    "    b_gener_co = tf.get_variable(\"variable1\", shape=[num_video]\n",
    "                                        , initializer=tf.random_normal_initializer(), dtype='float32')\n",
    "    b_gener_ou = tf.get_variable(\"variable2\", shape=[num_video]\n",
    "                                        , initializer=tf.random_normal_initializer(), dtype='float32')\n",
    "\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    assert tf.get_variable_scope().reuse==True\n",
    "    b_gener_co_2 = tf.get_variable(\"variable1\",shape=[num_video]\n",
    "                                          , dtype='float32')\n",
    "    b_gener_ou_2 = tf.get_variable(\"variable2\",shape=[num_video]\n",
    "                                          , dtype='float32')\n",
    "\n",
    "with tf.variable_scope(\"biases_disc\"):\n",
    "    b_disc_co = tf.get_variable(\"variable1\", shape=[n_user_feature]\n",
    "                                        , initializer=tf.random_normal_initializer(), dtype='float32',)\n",
    "    b_disc_ou_1 = tf.get_variable(\"variable2\", shape=[n_user_feature]\n",
    "                                        , initializer=tf.random_normal_initializer(), dtype='float32')\n",
    "    b_disc_ou_2 = tf.get_variable(\"variable3\", shape=[1]\n",
    "                                        , initializer=tf.random_normal_initializer(), dtype='float32')\n",
    "\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    assert tf.get_variable_scope().reuse==True\n",
    "    b_disc_co_2 = tf.get_variable(\"variable1\",shape=[n_user_feature]\n",
    "                                          , dtype='float32')\n",
    "\n",
    "    b_disc_ou_1_2 = tf.get_variable(\"variable2\",shape=[n_user_feature]\n",
    "                                          , dtype='float32')\n",
    "    b_disc_ou_2_2 = tf.get_variable(\"variable3\", shape=[1]\n",
    "                                        , initializer=tf.random_normal_initializer(), dtype='float32')\n",
    "\n",
    "with tf.variable_scope(\"weights_disc\"):\n",
    "    W_disc_co = tf.get_variable(\"variable1\", shape=[n_user_feature ,n_user_feature]\n",
    "                                        , initializer=tf.random_normal_initializer(), dtype='float32')\n",
    "    W_disc_ou = tf.get_variable(\"variable2\" ,shape=([n_hidden ,n_user_feature])\n",
    "                                        , initializer=tf.random_normal_initializer(), dtype='float32')\n",
    "    W_disc_ou_2 = tf.get_variable(\"variable3\" ,shape=([n_user_feature ,1])\n",
    "                                        , initializer=tf.random_normal_initializer(), dtype='float32')\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    assert tf.get_variable_scope().reuse==True\n",
    "\n",
    "    W_disc_co_2 = tf.get_variable(\"variable1\",shape=[n_user_feature ,n_user_feature]\n",
    "                                          , dtype='float32')\n",
    "    W_disc_ou_1_2 = tf.get_variable(\"variable2\", shape=[n_hidden ,n_user_feature]\n",
    "                                   , dtype='float32')\n",
    "    W_disc_ou_2_2 = tf.get_variable(\"variable3\", shape=[n_user_feature ,1]\n",
    "                                   , dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_train_gener(dynam_input, const_input, max_batch_length\n",
    "        ,W_gener_co ,W_gener_ou ,b_gener_co, b_gener_ou ,model):\n",
    "    with tf.variable_scope('bb') as scope:\n",
    "        lstm_cell = rnn_model(model ,n_hidden ,layers)\n",
    "        outputs ,states = tf.nn.dynamic_rnn(lstm_cell ,inputs = dynam_input\n",
    "                             ,dtype = tf.float32 ,sequence_length = max_batch_length)\n",
    "\n",
    "    out_shaped = tf.reshape(outputs ,[-1 ,n_hidden])\n",
    "    lay_2 = tf.reshape(tf.reshape(tf.matmul(out_shaped ,W_gener_ou) + b_gener_ou\n",
    "               ,[-1,batch_size,num_video]) + (tf.matmul(const_input,\n",
    "                                                        W_gener_co) + b_gener_co), [-1,num_video]) \n",
    "    \n",
    "\n",
    "    return (lay_2 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reinforce_disc(inp, const_input, max_batch_length, W_disc_co, W_disc_ou, W_disc_ou_2, b_disc_co\n",
    "                   , b_disc_ou_1, b_disc_ou_2, model):\n",
    "    try:\n",
    "        with tf.variable_scope('aa') as scope:\n",
    "            lstm_cell = rnn_model(model ,n_hidden ,layers)\n",
    "            outputs ,states = tf.nn.dynamic_rnn(lstm_cell ,inputs = inp\n",
    "                                 ,dtype = tf.float32 ,sequence_length = max_batch_length)\n",
    "    except:\n",
    "        with tf.variable_scope('dd') as scope:\n",
    "            lstm_cell = rnn_model(model ,n_hidden ,layers)\n",
    "            outputs ,states = tf.nn.dynamic_rnn(lstm_cell ,inputs = inp\n",
    "                                 ,dtype = tf.float32 ,sequence_length = max_batch_length)\n",
    "   \n",
    "    out_shaped = tf.reshape(outputs ,[-1 ,n_hidden])\n",
    "    \n",
    "    lay_2 = tf.reshape(tf.reshape(tf.matmul(out_shaped ,W_disc_ou) + b_disc_ou_1, [-1, batch_size, n_user_feature]) \n",
    "                       + (tf.matmul(const_input, W_disc_co) + b_disc_co), [-1,n_user_feature])\n",
    "    \n",
    "    \n",
    "    lay_3 = tf.matmul(lay_2 ,W_disc_ou_2) + b_disc_ou_2\n",
    "    \n",
    "    return (lay_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reinforce_gener(inp, const_input, max_batch_length,\n",
    "        W_gener_co_2, W_gener_ou_2, b_gener_co_2, b_gener_ou_2, model, _maxx):\n",
    "    lstm_cell = rnn_model(model ,n_hidden ,layers)\n",
    "\n",
    "    outputs ,states = tf.nn.dynamic_rnn(lstm_cell ,inputs = dynam_input\n",
    "                             ,dtype = tf.float32 ,sequence_length = max_batch_length)\n",
    "\n",
    "    with tf.variable_scope('cc') as scope:\n",
    "        lstm_cell = rnn_model(model ,n_hidden ,layers)\n",
    "        outputs ,states = tf.nn.dynamic_rnn(lstm_cell ,inputs = dynam_input\n",
    "                             ,dtype = tf.float32 ,sequence_length = max_batch_length)\n",
    "\n",
    "   \n",
    "    out_shaped = tf.reshape(outputs ,[-1 ,n_hidden])\n",
    "    lay_2 = tf.reshape(tf.reshape(tf.matmul(out_shaped ,W_gener_ou_2) + b_gener_ou_2\n",
    "               ,[-1,batch_size,num_video]) + (tf.matmul(const_input,\n",
    "                                                        W_gener_co_2) + b_gener_co_2), [-1,num_video]) \n",
    "    \n",
    "   \n",
    "    lay_3 = tf.nn.softmax(lay_2)\n",
    "    lay_4 = tf.reduce_max(lay_3, 1)\n",
    "    return (lay_3, lay_4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_gener, y_pred_gen_max = reinforce_gener(inp, const_input, max_batch_length,\n",
    "        W_gener_co_2, W_gener_ou_2, b_gener_co_2, b_gener_ou_2, model, _maxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = pre_train_gener(dynam_input, const_input \n",
    "        ,max_batch_length, W_gener_co, W_gener_ou, b_gener_co, b_gener_ou, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " disc_pred_gen = reinforce_disc(inp, const_input, max_batch_length, W_disc_co, W_disc_ou, W_disc_ou_2, b_disc_co\n",
    "                   , b_disc_ou_1, b_disc_ou_2, model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disc_pred_real = reinforce_disc(inp, const_input, max_batch_length, W_disc_co_2, W_disc_ou_1_2, W_disc_ou_2_2\n",
    "                                , b_disc_co_2, b_disc_ou_1_2, b_disc_ou_2_2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decays = tf.tile(tf.exp(tf.log(reward_gamma) * tf.to_float(tf.range((_maxx)))), [batch_size])\n",
    "prob_disc_gen = tf.sigmoid(disc_pred_gen_ph)\n",
    "rewards = tf.matmul(block_mat, tf.reshape(tf.reshape(tf.reshape(decays,[-1,1]) * prob_disc_gen, [-1]), [-1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('bpr_max'):\n",
    "    target_ind = tf.gather_nd(params = tf.reshape(y_pred, [-1, num_video]), indices = tr_rw_n_desired_rep)\n",
    "    relevant_y_pred = tf.reshape(tf.gather(params = tf.reshape(y_pred\n",
    "                                                    , [-1 ,num_video]), indices = tr_rw), [-1, num_video])\n",
    "    top_neg_vals, top_neg_indice = tf.nn.top_k(relevant_y_pred, n_samples)\n",
    "    softmax_scores = tf.reshape(tf.nn.softmax(top_neg_vals),[-1])\n",
    "    loss = tf.reduce_mean(-tf.log(tf.reduce_sum(tf.multiply(tf.sigmoid(tf.subtract(target_ind\n",
    "                                                            , tf.reshape(top_neg_vals, [-1])))\n",
    "                                                            ,softmax_scores))))\n",
    "    regularizer = tf.nn.l2_loss(tf.abs(W_gener_ou))\n",
    "    p_wise = tf.reduce_mean(loss + beta * regularizer)\n",
    "\n",
    "with tf.name_scope('loss_gen'):\n",
    "    g_loss = -tf.reduce_mean(tf.log(y_pred_gen_max) * rewards)\n",
    "\n",
    "with tf.name_scope('loss_d_gen'):\n",
    "       loss_d_gen = tf.reduce_mean(tf.multiply(\n",
    "         tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "             logits = disc_pred_gen, labels = tf.zeros([tf.shape(disc_pred_gen)[0], 1])), rows_t))\n",
    "\n",
    "with tf.name_scope('loss_d_real'):\n",
    "       loss_d_real = tf.reduce_mean(tf.multiply(\n",
    "         tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "             logits = disc_pred_real, labels = tf.ones([tf.shape(disc_pred_real)[0], 1])), rows_t))\n",
    "\n",
    "with tf.name_scope('train_d_real'):    \n",
    "    optimizer_d_r = tf.train.GradientDescentOptimizer(learning_rate = lr_rat).minimize(loss_d_real)\n",
    "\n",
    "with tf.name_scope('train_d_gen'):    \n",
    "    optimizer_d_gen = tf.train.GradientDescentOptimizer(learning_rate = lr_rat).minimize(loss_d_gen) \n",
    "\n",
    "with tf.name_scope('train_gen'):    \n",
    "    optimizer_gen = tf.train.GradientDescentOptimizer(learning_rate = lr_rat).minimize(g_loss)\n",
    "    \n",
    "with tf.name_scope('pre_train_gen'):    \n",
    "    optimizer_gen_pre = tf.train.AdamOptimizer(learning_rate = lr_rat).minimize(p_wise)  \n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    top_15_indx = tf.slice(top_neg_indice,[0,0],[-1, top_k])\n",
    "    to_bool = tf.reduce_sum(tf.cast(tf.equal(y_true, top_15_indx), tf.float32), 1)\n",
    "    accuracy = tf.reduce_mean(to_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar(\"loss_d_real\", loss_d_real)\n",
    "tf.summary.scalar(\"loss_d_gen\", loss_d_gen)\n",
    "tf.summary.scalar(\"loss_gen\", g_loss)\n",
    "tf.summary.scalar(\"bpr_max\", loss)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "summary_op = tf.summary.merge_all()\n",
    "writer_opt = tf.summary.FileWriter(logs_path, graph = tf.get_default_graph())\n",
    "saver = tf.train.Saver(write_version = tf.train.SaverDef.V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session() \n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./reco_rnn/GAN/accu\n"
     ]
    }
   ],
   "source": [
    "save_MDir = './reco_rnn/GAN/'\n",
    "save_model = os.path.join(save_MDir,'accu')\n",
    "sess=tf.Session() \n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess = sess, save_path= save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_steps = 1\n",
    "d_steps = 1\n",
    "proportion_supervised = 0.5\n",
    "proportion_generated = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/lib/python2.7/dist-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/lib/python2.7/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/lib/python2.7/dist-packages/ipykernel_launcher.py:25: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/usr/lib/python2.7/dist-packages/ipykernel_launcher.py:38: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 4 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n",
      "epoch number: 9 accuracy: 0.00131475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/ipykernel_launcher.py:48: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 14 accuracy: 0.0574163\n",
      "epoch number: 14 accuracy: 0.0332046\n",
      "epoch number: 14 accuracy: 0.0455355\n",
      "epoch number: 14 accuracy: 0.0314176\n",
      "epoch number: 14 accuracy: 0.0314176\n",
      "epoch number: 14 accuracy: 0.0791925\n",
      "epoch number: 14 accuracy: 0.0817949\n",
      "epoch number: 14 accuracy: 0.0817949\n",
      "epoch number: 14 accuracy: 0.0762195\n",
      "epoch number: 14 accuracy: 0.0492126\n",
      "epoch number: 14 accuracy: 0.0492126\n",
      "epoch number: 14 accuracy: 0.0492126\n",
      "epoch number: 14 accuracy: 0.0492126\n",
      "epoch number: 14 accuracy: 0.0492126\n",
      "epoch number: 14 accuracy: 0.0492126\n",
      "epoch number: 14 accuracy: 0.0492126\n",
      "epoch number: 14 accuracy: 0.0492126\n",
      "epoch number: 14 accuracy: 0.063056\n",
      "epoch number: 14 accuracy: 0.063056\n",
      "epoch number: 14 accuracy: 0.063056\n",
      "epoch number: 14 accuracy: 0.0433276\n",
      "epoch number: 14 accuracy: 0.0655658\n",
      "epoch number: 14 accuracy: 0.0371997\n",
      "epoch number: 14 accuracy: 0.0892252\n",
      "epoch number: 14 accuracy: 0.0892252\n",
      "epoch number: 14 accuracy: 0.120469\n",
      "epoch number: 14 accuracy: 0.120469\n",
      "epoch number: 14 accuracy: 0.0492386\n",
      "epoch number: 14 accuracy: 0.0365147\n",
      "epoch number: 14 accuracy: 0.0469268\n",
      "epoch number: 14 accuracy: 0.0699199\n",
      "epoch number: 14 accuracy: 0.0616126\n",
      "epoch number: 14 accuracy: 0.0501567\n",
      "epoch number: 14 accuracy: 0.0505992\n",
      "epoch number: 14 accuracy: 0.0355898\n",
      "epoch number: 14 accuracy: 0.0355898\n",
      "epoch number: 14 accuracy: 0.0355898\n",
      "epoch number: 14 accuracy: 0.05861\n",
      "epoch number: 14 accuracy: 0.05861\n",
      "epoch number: 14 accuracy: 0.0568622\n",
      "epoch number: 14 accuracy: 0.0568622\n",
      "epoch number: 14 accuracy: 0.0568622\n",
      "epoch number: 14 accuracy: 0.0888445\n",
      "epoch number: 14 accuracy: 0.0578575\n",
      "epoch number: 14 accuracy: 0.0805195\n",
      "epoch number: 14 accuracy: 0.0805195\n",
      "epoch number: 14 accuracy: 0.0805195\n",
      "epoch number: 14 accuracy: 0.0805195\n",
      "epoch number: 14 accuracy: 0.0599174\n",
      "epoch number: 14 accuracy: 0.0599174\n",
      "epoch number: 14 accuracy: 0.0599174\n",
      "epoch number: 14 accuracy: 0.0358187\n",
      "epoch number: 14 accuracy: 0.0358187\n",
      "epoch number: 14 accuracy: 0.0575521\n",
      "epoch number: 14 accuracy: 0.0450935\n",
      "epoch number: 14 accuracy: 0.0586181\n",
      "epoch number: 14 accuracy: 0.0275138\n",
      "epoch number: 14 accuracy: 0.0275138\n",
      "epoch number: 14 accuracy: 0.0275138\n",
      "epoch number: 14 accuracy: 0.0275138\n",
      "epoch number: 14 accuracy: 0.0432855\n",
      "epoch number: 14 accuracy: 0.0443267\n",
      "epoch number: 14 accuracy: 0.0747198\n",
      "epoch number: 14 accuracy: 0.0747198\n",
      "epoch number: 14 accuracy: 0.0356221\n",
      "epoch number: 14 accuracy: 0.0805723\n",
      "epoch number: 14 accuracy: 0.0805723\n",
      "epoch number: 14 accuracy: 0.0805723\n",
      "epoch number: 14 accuracy: 0.0805723\n",
      "epoch number: 14 accuracy: 0.0426746\n",
      "epoch number: 14 accuracy: 0.0426746\n",
      "epoch number: 14 accuracy: 0.0474252\n",
      "epoch number: 14 accuracy: 0.0474252\n",
      "epoch number: 14 accuracy: 0.0474252\n",
      "epoch number: 14 accuracy: 0.0504451\n",
      "epoch number: 14 accuracy: 0.0407104\n",
      "epoch number: 14 accuracy: 0.0407104\n",
      "epoch number: 14 accuracy: 0.0522577\n",
      "epoch number: 14 accuracy: 0.0522577\n",
      "epoch number: 14 accuracy: 0.0522577\n",
      "epoch number: 14 accuracy: 0.0387179\n",
      "epoch number: 14 accuracy: 0.0359043\n",
      "epoch number: 14 accuracy: 0.0411244\n",
      "epoch number: 14 accuracy: 0.0411244\n",
      "epoch number: 14 accuracy: 0.0170683\n",
      "epoch number: 14 accuracy: 0.0170683\n",
      "epoch number: 14 accuracy: 0.0170683\n",
      "epoch number: 14 accuracy: 0.0170683\n",
      "epoch number: 14 accuracy: 0.0799898\n",
      "epoch number: 14 accuracy: 0.030426\n",
      "epoch number: 14 accuracy: 0.030426\n",
      "epoch number: 14 accuracy: 0.030426\n",
      "epoch number: 14 accuracy: 0.0397461\n",
      "epoch number: 14 accuracy: 0.0397461\n",
      "epoch number: 14 accuracy: 0.121813\n",
      "epoch number: 14 accuracy: 0.121813\n",
      "epoch number: 14 accuracy: 0.0456421\n",
      "epoch number: 14 accuracy: 0.0456421\n",
      "epoch number: 14 accuracy: 0.036564\n",
      "epoch number: 14 accuracy: 0.0637636\n",
      "epoch number: 19 accuracy: 0.0555421\n",
      "epoch number: 19 accuracy: 0.0555421\n",
      "epoch number: 19 accuracy: 0.0555421\n",
      "epoch number: 19 accuracy: 0.0555421\n",
      "epoch number: 19 accuracy: 0.113076\n",
      "epoch number: 19 accuracy: 0.113076\n",
      "epoch number: 19 accuracy: 0.113076\n",
      "epoch number: 19 accuracy: 0.113076\n",
      "epoch number: 19 accuracy: 0.0716715\n",
      "epoch number: 19 accuracy: 0.0716715\n",
      "epoch number: 19 accuracy: 0.0502866\n",
      "epoch number: 19 accuracy: 0.0409875\n",
      "epoch number: 19 accuracy: 0.0800192\n",
      "epoch number: 19 accuracy: 0.0584526\n",
      "epoch number: 19 accuracy: 0.0584526\n",
      "epoch number: 19 accuracy: 0.0343112\n",
      "epoch number: 19 accuracy: 0.0322171\n",
      "epoch number: 19 accuracy: 0.0642504\n",
      "epoch number: 19 accuracy: 0.0642504\n",
      "epoch number: 19 accuracy: 0.0642504\n",
      "epoch number: 19 accuracy: 0.0367954\n",
      "epoch number: 19 accuracy: 0.0367954\n",
      "epoch number: 19 accuracy: 0.115445\n",
      "epoch number: 19 accuracy: 0.115445\n",
      "epoch number: 19 accuracy: 0.115445\n",
      "epoch number: 19 accuracy: 0.0644907\n",
      "epoch number: 19 accuracy: 0.0644907\n",
      "epoch number: 19 accuracy: 0.0644907\n",
      "epoch number: 19 accuracy: 0.0417902\n",
      "epoch number: 19 accuracy: 0.0760842\n",
      "epoch number: 19 accuracy: 0.0703086\n",
      "epoch number: 19 accuracy: 0.0764997\n",
      "epoch number: 19 accuracy: 0.0656069\n",
      "epoch number: 19 accuracy: 0.0478126\n",
      "epoch number: 19 accuracy: 0.0478126\n",
      "epoch number: 19 accuracy: 0.0478126\n",
      "epoch number: 19 accuracy: 0.0407709\n",
      "epoch number: 19 accuracy: 0.039915\n",
      "epoch number: 19 accuracy: 0.0564024\n",
      "epoch number: 19 accuracy: 0.0564024\n",
      "epoch number: 19 accuracy: 0.0564024\n",
      "epoch number: 19 accuracy: 0.0564024\n",
      "epoch number: 19 accuracy: 0.0564024\n",
      "epoch number: 19 accuracy: 0.0564024\n",
      "epoch number: 19 accuracy: 0.0384416\n",
      "epoch number: 19 accuracy: 0.0384416\n",
      "epoch number: 19 accuracy: 0.0227043\n",
      "epoch number: 19 accuracy: 0.0227043\n",
      "epoch number: 19 accuracy: 0.0227043\n",
      "epoch number: 19 accuracy: 0.0227043\n",
      "epoch number: 19 accuracy: 0.0227043\n",
      "epoch number: 19 accuracy: 0.0446176\n",
      "epoch number: 19 accuracy: 0.0517609\n",
      "epoch number: 19 accuracy: 0.0470342\n",
      "epoch number: 19 accuracy: 0.0731707\n",
      "epoch number: 19 accuracy: 0.0295593\n",
      "epoch number: 19 accuracy: 0.0362426\n",
      "epoch number: 19 accuracy: 0.0688396\n",
      "epoch number: 19 accuracy: 0.0512945\n",
      "epoch number: 19 accuracy: 0.0696579\n",
      "epoch number: 19 accuracy: 0.0420461\n",
      "epoch number: 19 accuracy: 0.0420461\n",
      "epoch number: 19 accuracy: 0.0420461\n",
      "epoch number: 19 accuracy: 0.0420461\n",
      "epoch number: 19 accuracy: 0.0245799\n",
      "epoch number: 19 accuracy: 0.0245799\n",
      "epoch number: 19 accuracy: 0.0245799\n",
      "epoch number: 19 accuracy: 0.0245799\n",
      "epoch number: 19 accuracy: 0.0245799\n",
      "epoch number: 19 accuracy: 0.0245799\n",
      "epoch number: 19 accuracy: 0.0320745\n",
      "epoch number: 19 accuracy: 0.0422645\n",
      "epoch number: 19 accuracy: 0.0693299\n",
      "epoch number: 19 accuracy: 0.0317383\n",
      "epoch number: 19 accuracy: 0.0317383\n",
      "epoch number: 19 accuracy: 0.0317383\n",
      "epoch number: 19 accuracy: 0.0317383\n",
      "epoch number: 19 accuracy: 0.0317383\n",
      "epoch number: 19 accuracy: 0.0667553\n",
      "epoch number: 19 accuracy: 0.0433186\n",
      "epoch number: 19 accuracy: 0.0692835\n",
      "epoch number: 19 accuracy: 0.0556248\n",
      "epoch number: 19 accuracy: 0.0556248\n",
      "epoch number: 19 accuracy: 0.0556248\n",
      "epoch number: 19 accuracy: 0.0556248\n",
      "epoch number: 19 accuracy: 0.098506\n",
      "epoch number: 19 accuracy: 0.0485388\n",
      "epoch number: 19 accuracy: 0.0485388\n",
      "epoch number: 19 accuracy: 0.0458961\n",
      "epoch number: 19 accuracy: 0.0616601\n",
      "epoch number: 19 accuracy: 0.036855\n",
      "epoch number: 19 accuracy: 0.036855\n",
      "epoch number: 19 accuracy: 0.0504027\n",
      "epoch number: 19 accuracy: 0.0504027\n",
      "epoch number: 19 accuracy: 0.0495641\n",
      "epoch number: 19 accuracy: 0.0495641\n",
      "epoch number: 19 accuracy: 0.0495641\n",
      "epoch number: 19 accuracy: 0.0495641\n",
      "epoch number: 19 accuracy: 0.0495641\n",
      "epoch number: 19 accuracy: 0.0370913\n",
      "epoch number: 24 accuracy: 0.000926784\n",
      "epoch number: 24 accuracy: 0.000926784\n",
      "epoch number: 24 accuracy: 0.000926784\n",
      "epoch number: 24 accuracy: 0.00856302\n",
      "epoch number: 24 accuracy: 0.00599664\n",
      "epoch number: 24 accuracy: 0.0010296\n",
      "epoch number: 24 accuracy: 0.0010296\n",
      "epoch number: 24 accuracy: 0.0010296\n",
      "epoch number: 24 accuracy: 0.00498557\n",
      "epoch number: 24 accuracy: 0.00219085\n",
      "epoch number: 24 accuracy: 0.00179949\n",
      "epoch number: 24 accuracy: 0.00179949\n",
      "epoch number: 24 accuracy: 0.000987411\n",
      "epoch number: 24 accuracy: 0.000987411\n",
      "epoch number: 24 accuracy: 0.000987411\n",
      "epoch number: 24 accuracy: 0.00125976\n",
      "epoch number: 24 accuracy: 0.00125976\n",
      "epoch number: 24 accuracy: 0.00157895\n",
      "epoch number: 24 accuracy: 0.00157895\n",
      "epoch number: 24 accuracy: 0.00157895\n",
      "epoch number: 24 accuracy: 0.00371287\n",
      "epoch number: 24 accuracy: 0.00371287\n",
      "epoch number: 24 accuracy: 0.00371287\n",
      "epoch number: 24 accuracy: 0.00371287\n",
      "epoch number: 24 accuracy: 0.003276\n",
      "epoch number: 24 accuracy: 0.000251383\n",
      "epoch number: 24 accuracy: 0.00183198\n",
      "epoch number: 24 accuracy: 0.0017439\n",
      "epoch number: 24 accuracy: 0.00619612\n",
      "epoch number: 24 accuracy: 0.00253743\n",
      "epoch number: 24 accuracy: 0.00512295\n",
      "epoch number: 24 accuracy: 0.00053749\n",
      "epoch number: 24 accuracy: 0.000511117\n",
      "epoch number: 24 accuracy: 0.00360546\n",
      "epoch number: 24 accuracy: 0.00360546\n",
      "epoch number: 24 accuracy: 0.0010627\n",
      "epoch number: 24 accuracy: 0.0010627\n",
      "epoch number: 24 accuracy: 0.0010627\n",
      "epoch number: 24 accuracy: 0.00294985\n",
      "epoch number: 24 accuracy: 0.00304878\n",
      "epoch number: 24 accuracy: 0.000976801\n",
      "epoch number: 24 accuracy: 0.00630583\n",
      "epoch number: 24 accuracy: 0.0127827\n",
      "epoch number: 24 accuracy: 0.000483442\n",
      "epoch number: 24 accuracy: 0.00151477\n",
      "epoch number: 24 accuracy: 0.00470256\n",
      "epoch number: 24 accuracy: 0.00470256\n",
      "epoch number: 24 accuracy: 0.000766088\n",
      "epoch number: 24 accuracy: 0.000766088\n",
      "epoch number: 24 accuracy: 0.000766088\n",
      "epoch number: 24 accuracy: 0.000766088\n",
      "epoch number: 24 accuracy: 0.000766088\n",
      "epoch number: 24 accuracy: 0.00233281\n",
      "epoch number: 24 accuracy: 0.00233281\n",
      "epoch number: 24 accuracy: 0.00233281\n",
      "epoch number: 24 accuracy: 0.00126167\n",
      "epoch number: 24 accuracy: 0.00274931\n",
      "epoch number: 24 accuracy: 0.00274931\n",
      "epoch number: 24 accuracy: 0.001514\n",
      "epoch number: 24 accuracy: 0.001514\n",
      "epoch number: 24 accuracy: 0.001514\n",
      "epoch number: 24 accuracy: 0.00276104\n",
      "epoch number: 24 accuracy: 0.00103842\n",
      "epoch number: 24 accuracy: 0.00103842\n",
      "epoch number: 24 accuracy: 0.00100959\n",
      "epoch number: 24 accuracy: 0.00100959\n",
      "epoch number: 24 accuracy: 0.00100959\n",
      "epoch number: 24 accuracy: 0.00100959\n",
      "epoch number: 24 accuracy: 0.000547945\n",
      "epoch number: 24 accuracy: 0.000761228\n",
      "epoch number: 24 accuracy: 0.00100125\n",
      "epoch number: 24 accuracy: 0.00100125\n",
      "epoch number: 24 accuracy: 0.00100125\n",
      "epoch number: 24 accuracy: 0.00100125\n",
      "epoch number: 24 accuracy: 0.00103546\n",
      "epoch number: 24 accuracy: 0.00104767\n",
      "epoch number: 24 accuracy: 0.00104767\n",
      "epoch number: 24 accuracy: 0.00147638\n",
      "epoch number: 24 accuracy: 0.00763359\n",
      "epoch number: 24 accuracy: 0.00293255\n",
      "epoch number: 24 accuracy: 0.00293255\n",
      "epoch number: 24 accuracy: 0.00293255\n",
      "epoch number: 24 accuracy: 0.00293255\n",
      "epoch number: 24 accuracy: 0.000514139\n",
      "epoch number: 24 accuracy: 0.000514139\n",
      "epoch number: 24 accuracy: 0.00125502\n",
      "epoch number: 24 accuracy: 0.00936472\n",
      "epoch number: 24 accuracy: 0.00936472\n",
      "epoch number: 24 accuracy: 0.00160729\n",
      "epoch number: 24 accuracy: 0.00152014\n",
      "epoch number: 24 accuracy: 0.00158395\n",
      "epoch number: 24 accuracy: 0.00158395\n",
      "epoch number: 24 accuracy: 0.00158395\n",
      "epoch number: 24 accuracy: 0.00158395\n",
      "epoch number: 24 accuracy: 0.00163265\n",
      "epoch number: 24 accuracy: 0.00787195\n",
      "epoch number: 24 accuracy: 0.00103199\n",
      "epoch number: 24 accuracy: 0.00103199\n",
      "epoch number: 24 accuracy: 0.00125881\n",
      "epoch number: 24 accuracy: 0.00816024\n",
      "epoch number: 29 accuracy: 0.0\n",
      "epoch number: 29 accuracy: 0.0\n",
      "epoch number: 29 accuracy: 0.00502892\n",
      "epoch number: 29 accuracy: 0.00136649\n",
      "epoch number: 29 accuracy: 0.00136649\n",
      "epoch number: 29 accuracy: 0.00136649\n",
      "epoch number: 29 accuracy: 0.00136649\n",
      "epoch number: 29 accuracy: 0.00136649\n",
      "epoch number: 29 accuracy: 0.00136649\n",
      "epoch number: 29 accuracy: 0.00136649\n",
      "epoch number: 29 accuracy: 0.00164249\n",
      "epoch number: 29 accuracy: 0.00510595\n",
      "epoch number: 29 accuracy: 0.00103466\n",
      "epoch number: 29 accuracy: 0.000778008\n",
      "epoch number: 29 accuracy: 0.00125094\n",
      "epoch number: 29 accuracy: 0.00125094\n",
      "epoch number: 29 accuracy: 0.00125094\n",
      "epoch number: 29 accuracy: 0.00169164\n",
      "epoch number: 29 accuracy: 0.0106326\n",
      "epoch number: 29 accuracy: 0.00364488\n",
      "epoch number: 29 accuracy: 0.00364488\n",
      "epoch number: 29 accuracy: 0.00364488\n",
      "epoch number: 29 accuracy: 0.00175439\n",
      "epoch number: 29 accuracy: 0.000517063\n",
      "epoch number: 29 accuracy: 0.00221839\n",
      "epoch number: 29 accuracy: 0.00221839\n",
      "epoch number: 29 accuracy: 0.000241255\n",
      "epoch number: 29 accuracy: 0.00075815\n",
      "epoch number: 29 accuracy: 0.000522876\n",
      "epoch number: 29 accuracy: 0.000522876\n",
      "epoch number: 29 accuracy: 0.000522876\n",
      "epoch number: 29 accuracy: 0.00689655\n",
      "epoch number: 29 accuracy: 0.00247729\n",
      "epoch number: 29 accuracy: 0.0015528\n",
      "epoch number: 29 accuracy: 0.000995272\n",
      "epoch number: 29 accuracy: 0.000995272\n",
      "epoch number: 29 accuracy: 0.00226358\n",
      "epoch number: 29 accuracy: 0.00072692\n",
      "epoch number: 29 accuracy: 0.00072692\n",
      "epoch number: 29 accuracy: 0.00072692\n",
      "epoch number: 29 accuracy: 0.00072692\n",
      "epoch number: 29 accuracy: 0.000509814\n",
      "epoch number: 29 accuracy: 0.000509814\n",
      "epoch number: 29 accuracy: 0.000509814\n",
      "epoch number: 29 accuracy: 0.000509814\n",
      "epoch number: 29 accuracy: 0.000509814\n",
      "epoch number: 29 accuracy: 0.003108\n",
      "epoch number: 29 accuracy: 0.003108\n",
      "epoch number: 29 accuracy: 0.000748877\n",
      "epoch number: 29 accuracy: 0.000748877\n",
      "epoch number: 29 accuracy: 0.00129099\n",
      "epoch number: 29 accuracy: 0.00129099\n",
      "epoch number: 29 accuracy: 0.00381971\n",
      "epoch number: 29 accuracy: 0.00102067\n",
      "epoch number: 29 accuracy: 0.00500923\n",
      "epoch number: 29 accuracy: 0.00500923\n",
      "epoch number: 29 accuracy: 0.00500923\n",
      "epoch number: 29 accuracy: 0.00193845\n",
      "epoch number: 29 accuracy: 0.00210637\n",
      "epoch number: 29 accuracy: 0.00494098\n",
      "epoch number: 29 accuracy: 0.00494098\n",
      "epoch number: 29 accuracy: 0.00053135\n",
      "epoch number: 29 accuracy: 0.00148552\n",
      "epoch number: 29 accuracy: 0.0018548\n",
      "epoch number: 29 accuracy: 0.000503271\n",
      "epoch number: 29 accuracy: 0.000503271\n",
      "epoch number: 29 accuracy: 0.00186617\n",
      "epoch number: 29 accuracy: 0.00525938\n",
      "epoch number: 29 accuracy: 0.00525938\n",
      "epoch number: 29 accuracy: 0.00525938\n",
      "epoch number: 29 accuracy: 0.00525938\n",
      "epoch number: 29 accuracy: 0.00394011\n",
      "epoch number: 29 accuracy: 0.00989834\n",
      "epoch number: 29 accuracy: 0.00989834\n",
      "epoch number: 29 accuracy: 0.00557103\n",
      "epoch number: 29 accuracy: 0.00557103\n",
      "epoch number: 29 accuracy: 0.000788022\n",
      "epoch number: 29 accuracy: 0.00327154\n",
      "epoch number: 29 accuracy: 0.00483871\n",
      "epoch number: 29 accuracy: 0.00483871\n",
      "epoch number: 29 accuracy: 0.00483871\n",
      "epoch number: 29 accuracy: 0.00025974\n",
      "epoch number: 29 accuracy: 0.00025974\n",
      "epoch number: 29 accuracy: 0.00025974\n",
      "epoch number: 29 accuracy: 0.00025974\n",
      "epoch number: 29 accuracy: 0.00025974\n",
      "epoch number: 29 accuracy: 0.00130753\n",
      "epoch number: 29 accuracy: 0.00229533\n",
      "epoch number: 29 accuracy: 0.00229533\n",
      "epoch number: 29 accuracy: 0.00229533\n",
      "epoch number: 29 accuracy: 0.00100629\n",
      "epoch number: 29 accuracy: 0.00154719\n",
      "epoch number: 29 accuracy: 0.00146987\n",
      "epoch number: 29 accuracy: 0.00260688\n",
      "epoch number: 29 accuracy: 0.00413223\n",
      "epoch number: 29 accuracy: 0.00121507\n",
      "epoch number: 29 accuracy: 0.000507614\n",
      "epoch number: 29 accuracy: 0.000507614\n",
      "epoch number: 29 accuracy: 0.00185283\n",
      "epoch number: 29 accuracy: 0.00185283\n",
      "epoch number: 34 accuracy: 0.00511771\n",
      "epoch number: 34 accuracy: 0.00511771\n",
      "epoch number: 34 accuracy: 0.00222552\n",
      "epoch number: 34 accuracy: 0.00190217\n",
      "epoch number: 34 accuracy: 0.00131544\n",
      "epoch number: 34 accuracy: 0.00131544\n",
      "epoch number: 34 accuracy: 0.00131544\n",
      "epoch number: 34 accuracy: 0.000513743\n",
      "epoch number: 34 accuracy: 0.000513743\n",
      "epoch number: 34 accuracy: 0.000513743\n",
      "epoch number: 34 accuracy: 0.000513743\n",
      "epoch number: 34 accuracy: 0.000513743\n",
      "epoch number: 34 accuracy: 0.000513743\n",
      "epoch number: 34 accuracy: 0.000513743\n",
      "epoch number: 34 accuracy: 0.00121595\n",
      "epoch number: 34 accuracy: 0.0\n",
      "epoch number: 34 accuracy: 0.0\n",
      "epoch number: 34 accuracy: 0.00026824\n",
      "epoch number: 34 accuracy: 0.00107411\n",
      "epoch number: 34 accuracy: 0.00554156\n",
      "epoch number: 34 accuracy: 0.00554156\n",
      "epoch number: 34 accuracy: 0.00554156\n",
      "epoch number: 34 accuracy: 0.00484144\n",
      "epoch number: 34 accuracy: 0.00484144\n",
      "epoch number: 34 accuracy: 0.0015536\n",
      "epoch number: 34 accuracy: 0.0015536\n",
      "epoch number: 34 accuracy: 0.0015536\n",
      "epoch number: 34 accuracy: 0.0015536\n",
      "epoch number: 34 accuracy: 0.00259403\n",
      "epoch number: 34 accuracy: 0.00192911\n",
      "epoch number: 34 accuracy: 0.000736558\n",
      "epoch number: 34 accuracy: 0.000736558\n",
      "epoch number: 34 accuracy: 0.00339065\n",
      "epoch number: 34 accuracy: 0.0\n",
      "epoch number: 34 accuracy: 0.00296097\n",
      "epoch number: 34 accuracy: 0.00422886\n",
      "epoch number: 34 accuracy: 0.00174477\n",
      "epoch number: 34 accuracy: 0.000998253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 34 accuracy: 0.000257136\n",
      "epoch number: 34 accuracy: 0.000257136\n",
      "epoch number: 34 accuracy: 0.00496454\n",
      "epoch number: 34 accuracy: 0.0010698\n",
      "epoch number: 34 accuracy: 0.00256082\n",
      "epoch number: 34 accuracy: 0.00128205\n",
      "epoch number: 34 accuracy: 0.00290206\n",
      "epoch number: 34 accuracy: 0.00290206\n",
      "epoch number: 34 accuracy: 0.00290206\n",
      "epoch number: 34 accuracy: 0.00290206\n",
      "epoch number: 34 accuracy: 0.00290206\n",
      "epoch number: 34 accuracy: 0.00151477\n",
      "epoch number: 34 accuracy: 0.00284532\n",
      "epoch number: 34 accuracy: 0.00284532\n",
      "epoch number: 34 accuracy: 0.00854258\n",
      "epoch number: 34 accuracy: 0.00854258\n",
      "epoch number: 34 accuracy: 0.00274863\n",
      "epoch number: 34 accuracy: 0.00315228\n",
      "epoch number: 34 accuracy: 0.00315228\n",
      "epoch number: 34 accuracy: 0.000708885\n",
      "epoch number: 34 accuracy: 0.000708885\n",
      "epoch number: 34 accuracy: 0.00291005\n",
      "epoch number: 34 accuracy: 0.000991818\n",
      "epoch number: 34 accuracy: 0.000991818\n",
      "epoch number: 34 accuracy: 0.000991818\n",
      "epoch number: 34 accuracy: 0.000991818\n",
      "epoch number: 34 accuracy: 0.00206932\n",
      "epoch number: 34 accuracy: 0.00206932\n",
      "epoch number: 34 accuracy: 0.000529942\n",
      "epoch number: 34 accuracy: 0.000529942\n",
      "epoch number: 34 accuracy: 0.000529942\n",
      "epoch number: 34 accuracy: 0.000529942\n",
      "epoch number: 34 accuracy: 0.0\n",
      "epoch number: 34 accuracy: 0.00702106\n",
      "epoch number: 34 accuracy: 0.00702106\n",
      "epoch number: 34 accuracy: 0.00654622\n",
      "epoch number: 34 accuracy: 0.0015064\n",
      "epoch number: 34 accuracy: 0.0015064\n",
      "epoch number: 34 accuracy: 0.000761421\n",
      "epoch number: 34 accuracy: 0.000761421\n",
      "epoch number: 34 accuracy: 0.00148295\n",
      "epoch number: 34 accuracy: 0.00148295\n",
      "epoch number: 34 accuracy: 0.0124481\n",
      "epoch number: 34 accuracy: 0.00570244\n",
      "epoch number: 34 accuracy: 0.00570244\n",
      "epoch number: 34 accuracy: 0.000486145\n",
      "epoch number: 34 accuracy: 0.000486145\n",
      "epoch number: 34 accuracy: 0.00228891\n",
      "epoch number: 34 accuracy: 0.0\n",
      "epoch number: 34 accuracy: 0.00241935\n",
      "epoch number: 34 accuracy: 0.00224439\n",
      "epoch number: 34 accuracy: 0.00224439\n",
      "epoch number: 34 accuracy: 0.00224439\n",
      "epoch number: 34 accuracy: 0.00224439\n",
      "epoch number: 34 accuracy: 0.00100075\n",
      "epoch number: 34 accuracy: 0.00100075\n",
      "epoch number: 34 accuracy: 0.0020141\n",
      "epoch number: 34 accuracy: 0.00270869\n",
      "epoch number: 34 accuracy: 0.00270869\n",
      "epoch number: 34 accuracy: 0.00270869\n",
      "epoch number: 34 accuracy: 0.00152517\n",
      "epoch number: 34 accuracy: 0.00152517\n"
     ]
    }
   ],
   "source": [
    "with open('GAN_accuracy.csv', 'wb') as csvfile:\n",
    "    wr = csv.writer(csvfile, delimiter='\\t', lineterminator='\\n')\n",
    "    for epoch in range(int(n_opt_epoch)):\n",
    "        for batch_n in range(int(n_users / batch_size)):\n",
    "            rw_to_chose = np.random.choice(int(tr_users) ,batch_size ,replace = False)\n",
    "            const_tr = (sort_pd_df_by_ext_vec(user_feat_inp_w_key_df, rw_to_chose,\n",
    "                                              cols = ['user_id'])).drop(['user_id'], axis = 1)\n",
    "            x_tr = sort_pd_df_by_ext_vec(user_vid_time_vidfeat_sorted,\n",
    "                                          rw_to_chose, cols = ['user_id','rank'])\n",
    "            d_real_inp = sort_pd_df_by_ext_vec(y_tr_p_w, rw_to_chose, cols = ['user_id','rank'])\n",
    "            y_batch = sort_pd_df_by_ext_vec(tr_y ,rw_to_chose,cols = ['user_id','rank'])\n",
    "            length_vec = sort_pd_df_by_ext_vec(df = max_watch ,ext_sor_vec = rw_to_chose ,cols = ['user_id'])      \n",
    "            length_max = max(length_vec.iloc[:,1])\n",
    "            str_idx = algeb_geom_series(0 ,start = 0 ,jump = length_max ,length = batch_size)\n",
    "            end_idx = np.append(length_vec.iloc[0, 1] ,length_vec.iloc[1:, 1:] + str_idx[1:].reshape(batch_size-1, -1))\n",
    "            app_range = range_bet_col_t_col_n_append(str_idx, end_idx)\n",
    "            rows_ind = np.repeat(app_range, n_samples)\n",
    "            trial_size = (int(batch_size * length_max), n_feature)\n",
    "            trial_size_d = (int(batch_size * length_max), num_video)\n",
    "            zero_array_x = np.zeros(trial_size)\n",
    "            zero_array_d_r =np.zeros(trial_size_d) \n",
    "            _x_tr = np_pad_tr_x(x_tr.iloc[:,3:], batch_size, str_idx.astype(int),\n",
    "                                            zero_array_x, length_vec.iloc[:,1].astype(int))\n",
    "            rep_ind = np.concatenate((np.repeat(app_range, n_samples).reshape(-1, 1)\n",
    "                                      , np.repeat(y_batch['desired'], n_samples).reshape(-1, 1)), axis = 1)\n",
    "            d_real_inp = np_pad_tr_x(d_real_inp.iloc[:,3:-1], batch_size, str_idx.astype(int),\n",
    "                                            zero_array_d_r, length_vec.iloc[:,1].astype(int))\n",
    "\n",
    "            block_tri = block_tri_mat(int(length_max), batch_size)\n",
    "\n",
    "\n",
    "            if (epoch < 10): # pre_train \n",
    "                _, g_p_w, g_pred, acc_pre_tr = sess.run([optimizer_gen_pre, p_wise, y_pred, accuracy],                            \n",
    "                                                    feed_dict = {dynam_input: _x_tr.reshape(batch_size, -1, n_feature)\n",
    "                                                      ,const_input: const_tr \n",
    "                                                      ,tr_rw_n_desired_rep: rep_ind\n",
    "                                                      ,tr_rw : app_range.reshape(-1, 1) \n",
    "                                                      ,y_true: y_batch['desired'].reshape(-1, 1)\n",
    "                                                      ,max_batch_length: length_vec.iloc[:, 1]})\n",
    "            else:\n",
    "                for _ in range(g_steps):\n",
    "                    if np.random.random() < proportion_supervised:\n",
    "                        _, _g_p_w, _g_pred, acc = sess.run([optimizer_gen_pre, p_wise, y_pred, accuracy],      \n",
    "                                                      feed_dict = {dynam_input: _x_tr.reshape(batch_size, -1, n_feature)\n",
    "                                                      ,const_input: const_tr \n",
    "                                                      ,tr_rw_n_desired_rep: rep_ind\n",
    "                                                      ,tr_rw : app_range.reshape(-1, 1) \n",
    "                                                      ,y_true: y_batch['desired'].reshape(-1, 1)\n",
    "                                                      ,max_batch_length: length_vec.iloc[:, 1]})\n",
    "                    else: \n",
    "                        gen_xx = sess.run(y_pred_gener, feed_dict = {\n",
    "                                dynam_input: _x_tr.reshape(batch_size, -1, n_feature)\n",
    "                                                      ,const_input: const_tr \n",
    "                                                      ,max_batch_length: length_vec.iloc[:,1]\n",
    "                                                    })\n",
    "\n",
    "                        d_xx = sess.run(disc_pred_gen, feed_dict = {inp: gen_xx.reshape(batch_size, -1, num_video)\n",
    "                                ,const_input: const_tr\n",
    "                                ,max_batch_length: length_vec.iloc[:,1]})\n",
    "\n",
    "\n",
    "                        _, g_l, unsupervised_gen_x, _rewards = sess.run([optimizer_gen, g_loss, y_pred_gener, rewards]\n",
    "                                                                        , feed_dict = \n",
    "                                             {dynam_input: _x_tr.reshape(batch_size, -1, n_feature),\n",
    "                                                      _maxx: length_max, \n",
    "                                                      disc_pred_gen_ph: d_xx,\n",
    "                                                      block_mat: block_tri \n",
    "                                                      ,const_input: const_tr \n",
    "                                                      ,max_batch_length: length_vec.iloc[:, 1]})\n",
    "            if ((epoch >= 10) & (epoch <= 20)) :\n",
    "                 _, _disc_pred_real_pre, d_loss_pre = sess.run([optimizer_d_r, disc_pred_real, loss_d_real], feed_dict = \n",
    "                                                             {inp: d_real_inp.reshape(batch_size, -1, num_video)\n",
    "                                                              ,const_input: const_tr\n",
    "                                                              ,max_batch_length: length_vec.iloc[:,1]\n",
    "                                                              ,rows_t: rows_ind \n",
    "\n",
    "                            })\n",
    "\n",
    "            if (epoch > 20):\n",
    "                for _ in range(d_steps):\n",
    "                    if np.random.random() < proportion_generated:\n",
    "                        _gen_xx = sess.run(y_pred_gener, feed_dict = {\n",
    "                                dynam_input: _x_tr.reshape(batch_size, -1, n_feature)\n",
    "                                                      ,const_input: const_tr \n",
    "                                                      ,max_batch_length: length_vec.iloc[:,1]\n",
    "                                        })\n",
    "                        _, _disc_pred_gen, d_loss = sess.run([optimizer_d_gen, disc_pred_gen, loss_d_gen], feed_dict = \n",
    "                                                       {inp: _gen_xx.reshape(batch_size, -1, num_video)\n",
    "                                                        ,const_input: const_tr\n",
    "                                                        ,max_batch_length: length_vec.iloc[:,1]\n",
    "                                                        ,rows_t: rows_ind})\n",
    "                    else:\n",
    "                        _, _disc_pred_real, _d_loss = sess.run([optimizer_d_r, disc_pred_real, loss_d_real], feed_dict = \n",
    "                                                             {inp: d_real_inp.reshape(batch_size, -1, num_video)\n",
    "                                                              ,const_input: const_tr\n",
    "                                                              ,max_batch_length: length_vec.iloc[:,1]\n",
    "                                                              ,rows_t: rows_ind \n",
    "\n",
    "                            })\n",
    "                    #wr.writerow([acc_pre_tr])\n",
    "            if ((epoch+1)%5 == 0):\n",
    "                print('epoch number:', epoch,'accuracy:', acc)\n",
    "                wr.writerow([acc])\n",
    "               \n",
    "        folder = './reco_rnn/GAN/'\n",
    "        save_path = saver.save(sess, folder + 'accu')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
