{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Package loading</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_pd_df_by_ext_vec(df, ext_sor_vec, cols):\n",
    "    df_s = df[((df[cols[0]]).astype(int)).isin(ext_sor_vec)] #\n",
    "    df_s['sort_cat'] = pd.Categorical(df_s[cols[0]],categories = ext_sor_vec,ordered = True)\n",
    "    if len(cols) > 1:\n",
    "        df_s.sort_values(['sort_cat',cols[1]] ,inplace = True)\n",
    "    \n",
    "    else:\n",
    "        df_s.sort_values(['sort_cat'],inplace = True) \n",
    "    \n",
    "    df_s.reset_index(inplace = True)\n",
    "    df_ = df_s.drop(['sort_cat','index'] ,axis = 1)\n",
    "    \n",
    "    return(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainSamples(viewers, videos, probab, viewerFeat, videoFeat, contxFeat):\n",
    "    trData = {} # trData = Dictionary with training data. This is histrory of viewer and video iteraction\n",
    "    X = {} # X  = Dictionary with viewer features as arrays\n",
    "    Y ={} # Y  = Dictionary with video features as arrays\n",
    "    for i in range(viewers):\n",
    "        X[i] = np.random.rand(viewerFeat)\n",
    "        a = 0 # timing of the video for a particular user,... \n",
    "                #to give the order in which the videos have been watched\n",
    "        for j in range(videos):\n",
    "            if int(np.random.binomial(1,probab ,1)[0]):\n",
    "                trData[(i,j,a)] = np.random.rand(contxFeat)\n",
    "                a+=1 # when a video is watched, we increase the value of a by 1 \n",
    "            if i==0:\n",
    "                Y[j] = np.random.rand(videoFeat)\n",
    "    return X,Y,trData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viewers = 1000  #number of viewers\n",
    "videos =1000  #number of videos\n",
    "probab = 0.05  #probability of a viewer watching any one video\n",
    "viewerFeat = 310  #number of features describing a veiwer\n",
    "videoFeat = 300   #number of features describing a video\n",
    "contxFeat = 15 # number of contextual features\n",
    "# X  = Dictionary with viewer features as arrays\n",
    "# Y  = Dictionary with video features as arrays\n",
    "# trData = Dictionary with training data. This is histrory of viewer and video iteraction\n",
    "X ,Y ,trData = trainSamples(viewers ,videos ,probab ,viewerFeat ,videoFeat ,contxFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_feat_inp = np.array([X[key] for key in sorted(X.keys())]) \n",
    "vid_feat_inp = np.array([Y[key] for key in sorted(Y.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_user = np.asarray(range(user_feat_inp.shape[0])).reshape(user_feat_inp.shape[0] ,1)\n",
    "key_vid = np.asarray(range(vid_feat_inp.shape[0])).reshape(vid_feat_inp.shape[0] ,1)\n",
    "user_feat_inp_w_key = np.concatenate((user_feat_inp ,key_user),axis = 1)\n",
    "vid_feat_inp_w_key = np.concatenate((vid_feat_inp ,key_vid),axis = 1)\n",
    "user_vid_time = trData.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_feat_inp_w_key_df = pd.DataFrame(user_feat_inp_w_key) \n",
    "vid_feat_inp_w_key_df = pd.DataFrame(vid_feat_inp_w_key)\n",
    "user_vid_time_df = pd.DataFrame(user_vid_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rr = user_vid_time_df.sort_values([0 ,2]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies_col = pd.get_dummies(rr[1],prefix = 'vid_')\n",
    "y_tr = pd.concat([rr.reset_index(drop = True), dummies_col], axis = 1)\n",
    "y_tr.rename(columns = {0: 'user'}, inplace = True)\n",
    "y_tr.rename(columns = {1: 'mov'}, inplace = True)\n",
    "y_tr.rename(columns = {2: 'rank'}, inplace = True)\n",
    "y_tr['desired'] = np.argmax(np.array(y_tr.iloc[:,4:]) ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_watch = (y_tr.groupby('user',axis = 0).sum().iloc[:\n",
    "                                ,int(np.array(np.where(y_tr.columns=='rank'))):-1].sum(axis=1)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vid_feat_inp_w_key_df.rename(columns = {300: 'mov_id'}, inplace = True)\n",
    "user_feat_inp_w_key_df.rename(columns = {310: 'user_id'}, inplace = True)\n",
    "user_vid_time_df.rename(columns = {0: 'user_id'}, inplace = True)\n",
    "user_vid_time_df.rename(columns = {1: 'mov_id'}, inplace = True)\n",
    "user_w_vid_tim_and_feat = user_vid_time_df.merge(user_feat_inp_w_key_df \n",
    "                                                 ,how = 'inner',on = 'user_id', sort = False)\n",
    "user_vid_time_vidfeat_usefit = user_w_vid_tim_and_feat.merge(vid_feat_inp_w_key_df \n",
    "                                                             ,how = 'inner' ,on='mov_id' ,sort = False)\n",
    "user_vid_time_vidfeat_usefit.rename(columns={'2_x': 'time_watch'} ,inplace=True)\n",
    "user_vid_time_vidfeat_usefit_sorted = user_vid_time_vidfeat_usefit.sort_values(['user_id', 'time_watch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_users = viewers * 0.8\n",
    "tr_y = y_tr[y_tr['user'] < tr_users]\n",
    "te_y = y_tr[~y_tr['user'].isin(tr_y['user'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_videos = len(y_tr.iloc[1,3:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_matrix = (y_tr.groupby('user').sum()).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utility_matrix_tr  = tr_y.groupby('user').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utility_matrix_te = te_y.groupby('user').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_utility_matrix = utility_matrix.reset_index().iloc[:,3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_utility_matrix_tr = utility_matrix_tr.reset_index().iloc[:,3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_utility_matrix_te = utility_matrix_te.reset_index().iloc[:,3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = viewers\n",
    "top_k = 15\n",
    "top_r = 5\n",
    "top_l = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_utility_mat = tf.placeholder(tf.float32, shape=[tr_users ,num_videos], name=\"input_placeholder_a\")\n",
    "top_all_in = tf.placeholder(tf.int32, shape=[num_videos, num_videos], name='sim_mat')\n",
    "top_k_in = tf.placeholder(tf.int32, shape=[num_videos ,top_k], name=\"similarity_matrix_k\")\n",
    "top_r_in = tf.placeholder(tf.int32, shape=[num_videos ,top_r], name=\"similarity_matrix_r\")\n",
    "top_l_in = tf.placeholder(tf.int32, shape=[num_videos ,top_l], name=\"similarity_matrix_l\")\n",
    "\n",
    "user_desire = tf.placeholder(tf.int32, shape=[None ,1], name=\"user_des\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalize_b = tf.nn.l2_normalize(item_utility_mat, 0)\n",
    "normalize_a = tf.transpose(normalize_b)        \n",
    "cos_similarity =(tf.matmul(normalize_a, normalize_b))\n",
    "top_vals_all ,top_all_indice = tf.nn.top_k(cos_similarity, num_videos, sorted=True)\n",
    "top_vals_k ,top_k_indice = tf.nn.top_k(cos_similarity, top_k, sorted=True)\n",
    "top_vals_r ,top_r_indice = tf.nn.top_k(cos_similarity, top_r, sorted=True)\n",
    "top_vals_l ,top_l_indice = tf.nn.top_k(cos_similarity, top_l, sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('user_accuracy'):\n",
    "    user_pred_r = tf.reshape(tf.gather(params = top_r_in, indices = user_desire), [-1, top_r])\n",
    "    to_cast_r = tf.cast(tf.equal(user_desire[1:], user_pred_r[:-1]), tf.float32)\n",
    "    user_accuracy_r = tf.reduce_sum(tf.reduce_sum(to_cast_r, 1))\n",
    "    \n",
    "    user_pred_l = tf.reshape(tf.gather(params = top_l_in, indices = user_desire), [-1, top_l])\n",
    "    to_cast_l = tf.cast(tf.equal(user_desire[1:], user_pred_l[:-1]), tf.float32)\n",
    "    user_accuracy_l = tf.reduce_sum(tf.reduce_sum(to_cast_l, 1))\n",
    "\n",
    "    user_pred_k = tf.reshape(tf.gather(params = top_k_in, indices = user_desire), [-1, top_k])\n",
    "    to_cast_k = tf.cast(tf.equal(user_desire[1:], user_pred_k[:-1]), tf.float32)\n",
    "    user_accuracy_k = tf.reduce_sum(tf.reduce_sum(to_cast_k, 1))\n",
    "\n",
    "with tf.name_scope('mean_reciprocal_rank_with_top_k'):\n",
    "    user_pred_all = tf.reshape(tf.gather(params = top_all_in, indices= user_desire), [-1,num_videos])\n",
    "    to_cast = tf.cast(tf.equal(user_desire[1:], user_pred_all[:-1]), tf.float32)\n",
    "    to_where = (tf.where(tf.equal(to_cast, tf.ones(shape=[tf.shape(to_cast)[0], 1]))))[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "t_r_idx, t_k_idx, t_l_idx, t_all_idx ,cos_sim = sess.run([top_r_indice \n",
    "                                      ,top_k_indice, top_l_indice , top_all_indice, cos_similarity], \n",
    "                                     feed_dict={item_utility_mat: _utility_matrix_tr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omer/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy k:', 0.012415574096146206)\n",
      "('Accuracy l:', 0.0078466428287644018)\n",
      "('Accuracy r:', 0.0034763607469209378)\n"
     ]
    }
   ],
   "source": [
    "with open('col_filter_item.csv', 'wb') as csvfile:\n",
    "    wr = csv.writer(csvfile, delimiter='\\t', lineterminator='\\n')\n",
    "    use_accu_r = []\n",
    "    use_accu_l = []\n",
    "    use_accu_k = []\n",
    "    use_mrr = []\n",
    "    for user in (te_y[\"user\"].unique()):\n",
    "        _user = (te_y[te_y['user']==user]['desired']).reshape(-1, 1)\n",
    "        pred_k, tr_mrr, acc_r, acc_k, acc_l  = sess.run([user_pred_k,to_where, user_accuracy_r, user_accuracy_k, user_accuracy_l]\n",
    "                                                , feed_dict = {top_r_in: t_r_idx\n",
    "                                                      , top_k_in: t_k_idx, top_l_in: t_l_idx, \n",
    "                                                                                 top_all_in: t_all_idx,  \n",
    "                                                                                  user_desire: _user})\n",
    "        \n",
    "        use_mrr.append(tr_mrr)\n",
    "        use_accu_r.append(acc_r)\n",
    "        use_accu_l.append(acc_l)\n",
    "        use_accu_k.append(acc_k)\n",
    "        wr.writerow([acc_r])\n",
    "        wr.writerow([acc_k])\n",
    "        wr.writerow([tr_mrr])\n",
    "    print ('Accuracy k:', sum(use_accu_k) / (te_y['desired'].shape[0]) )\n",
    "    print ('Accuracy l:', sum(use_accu_l) / (te_y['desired'].shape[0]) )\n",
    "    print ('Accuracy r:', sum(use_accu_r) / (te_y['desired'].shape[0]) )\n",
    "#     print ('MRR:', use_mrr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_mrr = []\n",
    "for user in range(len(use_mrr)):\n",
    "    mean_mrr.append(np.percentile(use_mrr[user],50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506.66250000000002"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_mrr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
